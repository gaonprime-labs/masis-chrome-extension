# clip-server/server.py
"""
CLIP Embedding Server
ì™„ì „ ë¬´ë£Œ ë¡œì»¬ CLIP ì„ë² ë”© ì„œë²„

Features:
- Text/Image ì„ë² ë”© ìƒì„±
- ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
- GPU/MPS/CPU ìë™ ê°ì§€
- LRU ìºì‹±
- CORS ì§€ì›
"""

import torch
from transformers import CLIPProcessor, CLIPModel
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from PIL import Image
import requests
from io import BytesIO
from typing import List, Literal, Optional
from functools import lru_cache
import logging
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="CLIP Embedding Server",
    description="ë¡œì»¬ CLIP ì„ë² ë”© ì„œë²„ (ì™„ì „ ë¬´ë£Œ)",
    version="1.0.0"
)

# CORS ì„¤ì • (Next.jsì—ì„œ ì ‘ê·¼ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "https://ark.gaonprime.com"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===== ë””ë°”ì´ìŠ¤ ì„¤ì • =====
def get_device():
    """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ì„ íƒ (GPU > MPS > CPU)"""
    if torch.cuda.is_available():
        device = "cuda"
        gpu_name = torch.cuda.get_device_name(0)
        logger.info(f"ğŸš€ Using NVIDIA GPU: {gpu_name}")
    elif torch.backends.mps.is_available():
        device = "mps"
        logger.info("ğŸš€ Using Apple Silicon GPU (MPS)")
    else:
        device = "cpu"
        logger.warning("âš ï¸  Using CPU (ëŠë¦° ì„±ëŠ¥)")
    return device

device = get_device()

# ===== CLIP ëª¨ë¸ ë¡œë“œ =====
MODEL_NAME = "openai/clip-vit-large-patch14"  # ViT-L/14
logger.info(f"ğŸ“¦ Loading CLIP model: {MODEL_NAME}")

try:
    model = CLIPModel.from_pretrained(MODEL_NAME).to(device)
    processor = CLIPProcessor.from_pretrained(MODEL_NAME)
    model.eval()  # í‰ê°€ ëª¨ë“œ
    logger.info("âœ… CLIP model loaded successfully")
except Exception as e:
    logger.error(f"âŒ Failed to load CLIP model: {e}")
    raise

# ===== ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ =====
class EmbeddingRequest(BaseModel):
    """ë‹¨ì¼ ì„ë² ë”© ìš”ì²­"""
    input: str = Field(..., description="í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ URL")
    type: Literal["text", "image"] = Field(..., description="ì„ë² ë”© íƒ€ì…")

class BatchEmbeddingRequest(BaseModel):
    """ë°°ì¹˜ ì„ë² ë”© ìš”ì²­"""
    inputs: List[str] = Field(..., description="í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ URL ëª©ë¡")
    type: Literal["text", "image"] = Field(..., description="ì„ë² ë”© íƒ€ì…")

class EmbeddingResponse(BaseModel):
    """ë‹¨ì¼ ì„ë² ë”© ì‘ë‹µ"""
    success: bool
    embedding: Optional[List[float]] = None
    error: Optional[str] = None
    processing_time: Optional[float] = None

class BatchEmbeddingResponse(BaseModel):
    """ë°°ì¹˜ ì„ë² ë”© ì‘ë‹µ"""
    success: bool
    embeddings: Optional[List[List[float]]] = None
    error: Optional[str] = None
    processing_time: Optional[float] = None

class HealthResponse(BaseModel):
    """í—¬ìŠ¤ì²´í¬ ì‘ë‹µ"""
    status: str
    device: str
    model: str
    torch_version: str

# ===== í—¬í¼ í•¨ìˆ˜ =====
@lru_cache(maxsize=100)
def download_image(url: str) -> Image.Image:
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (LRU ìºì‹±)"""
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        image = Image.open(BytesIO(response.content)).convert("RGB")
        return image
    except Exception as e:
        logger.error(f"âŒ Image download failed: {url} - {e}")
        raise

def create_text_embedding(text: str) -> List[float]:
    """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    # CLIP ìµœëŒ€ í† í° ê¸¸ì´ëŠ” 77ê°œ (truncation í•„ìš”)
    inputs = processor(text=[text], return_tensors="pt", padding=True, truncation=True, max_length=77).to(device)

    with torch.no_grad():
        text_features = model.get_text_features(**inputs)
        # L2 ì •ê·œí™”
        text_features = text_features / text_features.norm(p=2, dim=-1, keepdim=True)

    return text_features[0].cpu().numpy().tolist()

def create_image_embedding(image_url: str) -> List[float]:
    """ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±"""
    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ìºì‹±)
    image = download_image(image_url)

    # ì´ë¯¸ì§€ ì„ë² ë”©
    inputs = processor(images=image, return_tensors="pt").to(device)

    with torch.no_grad():
        image_features = model.get_image_features(**inputs)
        # L2 ì •ê·œí™”
        image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)

    return image_features[0].cpu().numpy().tolist()

def create_batch_text_embeddings(texts: List[str]) -> List[List[float]]:
    """ë°°ì¹˜ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    inputs = processor(text=texts, return_tensors="pt", padding=True, truncation=True, max_length=77).to(device)

    with torch.no_grad():
        text_features = model.get_text_features(**inputs)
        text_features = text_features / text_features.norm(p=2, dim=-1, keepdim=True)

    return text_features.cpu().numpy().tolist()

def create_batch_image_embeddings(image_urls: List[str]) -> List[List[float]]:
    """ë°°ì¹˜ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±"""
    # ë°°ì¹˜ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    images = [download_image(url) for url in image_urls]

    # ë°°ì¹˜ ì´ë¯¸ì§€ ì„ë² ë”©
    inputs = processor(images=images, return_tensors="pt").to(device)

    with torch.no_grad():
        image_features = model.get_image_features(**inputs)
        image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)

    return image_features.cpu().numpy().tolist()

# ===== API ì—”ë“œí¬ì¸íŠ¸ =====
@app.get("/", response_model=dict)
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "CLIP Embedding Server",
        "version": "1.0.0",
        "endpoints": {
            "health": "/health",
            "embed": "/embed",
            "batch": "/embed/batch"
        }
    }

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """í—¬ìŠ¤ì²´í¬"""
    return HealthResponse(
        status="healthy",
        device=device,
        model=MODEL_NAME,
        torch_version=torch.__version__
    )

@app.post("/embed", response_model=EmbeddingResponse)
async def create_embedding(request: EmbeddingRequest):
    """ë‹¨ì¼ ì„ë² ë”© ìƒì„±"""
    start_time = time.time()

    try:
        logger.info(f"ğŸ” Processing {request.type} embedding request")

        if request.type == "text":
            embedding = create_text_embedding(request.input)
        elif request.type == "image":
            embedding = create_image_embedding(request.input)
        else:
            raise HTTPException(status_code=400, detail="Invalid type")

        processing_time = time.time() - start_time
        logger.info(f"âœ… Embedding created in {processing_time:.2f}s")

        return EmbeddingResponse(
            success=True,
            embedding=embedding,
            processing_time=processing_time
        )

    except requests.RequestException as e:
        logger.error(f"âŒ Image download failed: {e}")
        return EmbeddingResponse(
            success=False,
            error=f"Failed to download image: {str(e)}"
        )
    except Exception as e:
        logger.error(f"âŒ Embedding failed: {e}")
        return EmbeddingResponse(
            success=False,
            error=f"Embedding generation failed: {str(e)}"
        )

@app.post("/embed/batch", response_model=BatchEmbeddingResponse)
async def create_batch_embeddings(request: BatchEmbeddingRequest):
    """ë°°ì¹˜ ì„ë² ë”© ìƒì„± (ì„±ëŠ¥ ìµœì í™”)"""
    start_time = time.time()

    try:
        logger.info(f"ğŸ” Processing batch of {len(request.inputs)} {request.type} embeddings")

        if request.type == "text":
            embeddings = create_batch_text_embeddings(request.inputs)
        elif request.type == "image":
            embeddings = create_batch_image_embeddings(request.inputs)
        else:
            raise HTTPException(status_code=400, detail="Invalid type")

        processing_time = time.time() - start_time
        logger.info(f"âœ… Batch embeddings created in {processing_time:.2f}s")

        return BatchEmbeddingResponse(
            success=True,
            embeddings=embeddings,
            processing_time=processing_time
        )

    except Exception as e:
        logger.error(f"âŒ Batch embedding failed: {e}")
        return BatchEmbeddingResponse(
            success=False,
            error=f"Batch embedding generation failed: {str(e)}"
        )

# ===== ë©”ì¸ ì‹¤í–‰ =====
if __name__ == "__main__":
    import uvicorn

    logger.info("ğŸš€ Starting CLIP Embedding Server...")

    uvicorn.run(
        app,
        host="0.0.0.0",  # ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©
        port=8000,
        log_level="info"
    )
